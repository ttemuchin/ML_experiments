{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nG8GuNGW94Ho",
        "outputId": "7a25db6c-15cc-4cab-81b5-b41213e05cc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymorphy3 in c:\\users\\ttemuchin4\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.0.3)\n",
            "Requirement already satisfied: nltk in c:\\users\\ttemuchin4\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.9.1)\n",
            "Requirement already satisfied: dawg2-python>=0.8.0 in c:\\users\\ttemuchin4\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pymorphy3) (0.9.0)\n",
            "Requirement already satisfied: pymorphy3-dicts-ru in c:\\users\\ttemuchin4\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pymorphy3) (2.4.417150.4580142)\n",
            "Requirement already satisfied: setuptools>=68.2.2 in c:\\users\\ttemuchin4\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pymorphy3) (75.6.0)\n",
            "Requirement already satisfied: click in c:\\users\\ttemuchin4\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in c:\\users\\ttemuchin4\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\ttemuchin4\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in c:\\users\\ttemuchin4\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\ttemuchin4\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk) (0.4.6)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "pip install pymorphy3 nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UyPLvbl-UBPq"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import nltk\n",
        "import pymorphy3\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm import tqdm\n",
        "from nltk.stem.snowball import RussianStemmer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6I6SVCFYICdk",
        "outputId": "6d38b56e-33cc-4ef0-b25d-c285ff51293c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\ttemuchin4\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tqdm.pandas()\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JHAwgaWBCp4A"
      },
      "outputs": [],
      "source": [
        "train_dataframe = pd.read_csv(\"./archive/train.csv\").iloc[:2000]\n",
        "valid_dataframe = pd.read_csv(\"./archive/test.csv\").iloc[:400]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGiKTX8FC6rY"
      },
      "outputs": [],
      "source": [
        "# train_dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xX7qoPbDJf9"
      },
      "outputs": [],
      "source": [
        "def preproc(text):\n",
        "  text = text.lower()\n",
        "  text = re.sub(r\"([^\\w\\s]\\s)\", r\" \\1\", text)\n",
        "  text = re.sub(r\"(\\d)\\.\", r\"\\1 . \", text)\n",
        "  text = re.sub(r\"\\s+\", r\" \", text)\n",
        "  text = text.strip()\n",
        "  text = text.split(\" \")\n",
        "# это лемантизация. стемминг еще дольше\n",
        "  morph = pymorphy3.MorphAnalyzer() \n",
        "  text = [morph.parse(word)[0].normal_form for word in text]\n",
        "\n",
        "  # stemmer = RussianStemmer()\n",
        "  # stemmed_words = [stemmer.stem(word) for word in text]\n",
        "\n",
        "  return text \n",
        "# получили набор токенов\n",
        "\n",
        "def slicingWindow(sequence):\n",
        "  pairs = []\n",
        "  for index, word in enumerate(sequence):\n",
        "    for jndex in [-2, -1, 1, 2]:\n",
        "      if 0 <= index+jndex < len(sequence):\n",
        "        pairs.append((sequence[index], sequence[index+jndex]))\n",
        "  return pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJhrUZ8prWmF",
        "outputId": "fef74c9a-604f-4423-878c-108b95d9c1de"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['волшебный',\n",
              " 'фото',\n",
              " 'виктория',\n",
              " 'поплавский',\n",
              " 'евгений',\n",
              " '.',\n",
              " '2',\n",
              " '.',\n",
              " '3',\n",
              " '.',\n",
              " '1']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preproc(\"Волшебные фото Виктория Поплавская Евгения. 2.3.1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhlSr4r3EFwV",
        "outputId": "ba23cb93-29fb-4ebd-83e0-4f3cb3ab559c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('волшебный', 'фото'),\n",
              " ('волшебный', 'виктория'),\n",
              " ('фото', 'волшебный'),\n",
              " ('фото', 'виктория'),\n",
              " ('фото', 'поплавский'),\n",
              " ('виктория', 'волшебный'),\n",
              " ('виктория', 'фото'),\n",
              " ('виктория', 'поплавский'),\n",
              " ('виктория', 'евгений'),\n",
              " ('поплавский', 'фото'),\n",
              " ('поплавский', 'виктория'),\n",
              " ('поплавский', 'евгений'),\n",
              " ('поплавский', '.'),\n",
              " ('евгений', 'виктория'),\n",
              " ('евгений', 'поплавский'),\n",
              " ('евгений', '.'),\n",
              " ('евгений', '2'),\n",
              " ('.', 'поплавский'),\n",
              " ('.', 'евгений'),\n",
              " ('.', '2'),\n",
              " ('.', '.'),\n",
              " ('2', 'евгений'),\n",
              " ('2', '.'),\n",
              " ('2', '.'),\n",
              " ('2', '3'),\n",
              " ('.', '.'),\n",
              " ('.', '2'),\n",
              " ('.', '3'),\n",
              " ('.', '.'),\n",
              " ('3', '2'),\n",
              " ('3', '.'),\n",
              " ('3', '.'),\n",
              " ('3', '1'),\n",
              " ('.', '.'),\n",
              " ('.', '3'),\n",
              " ('.', '1'),\n",
              " ('.', '.'),\n",
              " ('1', '3'),\n",
              " ('1', '.'),\n",
              " ('1', '.'),\n",
              " ('.', '.'),\n",
              " ('.', '1')]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"   Волшебные фото Виктория Поплавская Евгения.   2.3.1.  \"\n",
        "sequence_of_words = preproc(text)\n",
        "slicingWindow(sequence_of_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UQgltXaELGa",
        "outputId": "c48bf284-caa5-4487-a325-0677ef696aa8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/2000 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2000/2000 [02:49<00:00, 11.81it/s]\n",
            "100%|██████████| 2000/2000 [00:00<00:00, 18213.26it/s]\n",
            "100%|██████████| 400/400 [00:35<00:00, 11.34it/s]\n",
            "100%|██████████| 400/400 [00:00<00:00, 16384.32it/s]\n"
          ]
        }
      ],
      "source": [
        "train_pairs = train_dataframe[\"text\"].progress_apply(preproc).progress_apply(slicingWindow).explode().tolist()\n",
        "valid_pairs = valid_dataframe[\"text\"].progress_apply(preproc).progress_apply(slicingWindow).explode().tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "для чего пишем свой датасет наследуя от торч - когда в оперативку тяжело поместить, можно данные на диск\n",
        "\n",
        "в гет итем открываем только 1 ! файл и только он в оперативке\n",
        "\n",
        "батч - пачка записей на подачу в сеть. столько же и ответов\n",
        "\n",
        "даталоадер - позволяет превратить датасет в набор батчей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JPKkEWv1wt-D"
      },
      "outputs": [],
      "source": [
        "class MyDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, pairs):\n",
        "    self.pairs = pairs\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.pairs)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.pairs[index][0], self.pairs[index][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_HfxQoMp8SP"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "train_dataset = MyDataset(train_pairs)\n",
        "valid_dataset = MyDataset(valid_pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bew30vL9peJm"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "простой токенизатор для слов. есть два словаря - это не индексы слова в предложении, это все слова датасета и индексы для них"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "xKLtiiuiK4O8"
      },
      "outputs": [],
      "source": [
        "class Tokenizer:\n",
        "  def __init__(self, set_of_words):\n",
        "    self.__word2index = {}\n",
        "    self.__index2word = {}\n",
        "    for index, value in enumerate(set_of_words):\n",
        "      self.__word2index[value] = index\n",
        "      self.__index2word[index] = value\n",
        "\n",
        "  def __call__(self, sequence):\n",
        "    tokens = []\n",
        "    for word in sequence:\n",
        "      try:\n",
        "        tokens.append(self.__word2index[word.lower()])\n",
        "      except:\n",
        "        raise ValueError(\"Такого слова нет в токенизаторе\")\n",
        "    return torch.tensor(tokens)\n",
        "\n",
        "  def decode(self, sequence):\n",
        "    words = []\n",
        "    for index in sequence:\n",
        "      try:\n",
        "        words.append(self.__index2word[index])\n",
        "      except:\n",
        "        raise ValueError(\"Такого токена нет в токенизаторе\")\n",
        "    return words\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.__word2index)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "lkuOYL8k_lGR"
      },
      "outputs": [],
      "source": [
        "tokenizer_dataframe = pd.concat([train_dataframe[\"text\"], valid_dataframe[\"text\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdizgvEAH8Pk",
        "outputId": "706d907a-22ae-44d1-d20f-9a1d0a6d3712"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2400/2400 [02:51<00:00, 13.98it/s]\n"
          ]
        }
      ],
      "source": [
        "tokenizer = Tokenizer(set(tokenizer_dataframe.progress_apply(preproc).explode().tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vt0OpvJiKThy",
        "outputId": "38995dc0-2873-4e06-b9a8-a113ebeb52e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([15505,  4106,  5672,   384])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer(preproc(\"Привет меня зовут Руслан\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqjIGUfYMYC6",
        "outputId": "92f86883-4540-4f2f-e4c2-938cff99174b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "18728"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "архитектура модели\n",
        "энкодер декодер, эмбединги - хешмап, подаем токен как вектор oneHot. вектор умножается на матрицу - поэтому просто берем столбец по индексу. это и есть эмбединг слова. потом расщифровываем его\n",
        "\n",
        "в инициализации прописываем создание весов, а в форвард то как данные идут по весам\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTCn8nQKNDeU"
      },
      "outputs": [],
      "source": [
        "class word2vec(nn.Module):\n",
        "  def __init__(self, num_dict, hidden):\n",
        "    super().__init__()\n",
        "    self.encode = nn.Embedding(num_dict, hidden) # 18728 x 300\n",
        "    self.decode = nn.Linear(hidden, num_dict)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.encode(x)\n",
        "    out = self.decode(out)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "fr3TeEeMoO_i"
      },
      "outputs": [],
      "source": [
        "num_dict = 18728\n",
        "hidden = 300"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "kBRa7H_ToAEq"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = word2vec(num_dict, hidden).to(device)\n",
        "optim = torch.optim.Adam(model.parameters(), lr=3e-4) #модно молодежно\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "epochs = range(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCn45buN6fIa",
        "outputId": "9d4c7473-15e6-4cea-afb4-49500a17635b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "sdIXc3mKoYqj"
      },
      "outputs": [],
      "source": [
        "train_loss_list = []\n",
        "valid_loss_list = []\n",
        "train_acc_list = []\n",
        "valid_acc_list = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6DryuWrzwi7",
        "outputId": "1f32c86b-c48f-469b-8d82-58add1a9dac3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 23%|██▎       | 7001/31061 [06:34<22:36, 17.73it/s, Loss=8.73, Accuracy=0]     \n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[29], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m target \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mone_hot(target, num_classes\u001b[38;5;241m=\u001b[39mnum_dict)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m     21\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(out, target)\n\u001b[1;32m---> 22\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m train_loss_mean \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     25\u001b[0m optim\u001b[38;5;241m.\u001b[39mstep()\n",
            "File \u001b[1;32mc:\\Users\\ttemuchin4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    625\u001b[0m     )\n\u001b[1;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\ttemuchin4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\ttemuchin4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for epoch in epochs:\n",
        "  print(f\"Epochs {epoch}\")\n",
        "\n",
        "  train_loss_mean = 0\n",
        "  valid_loss_mean = 0\n",
        "  train_acc_mean = 0\n",
        "  valid_acc_mean = 0\n",
        "\n",
        "  for data, target in (pbar := tqdm(train_dataloader)):\n",
        "    optim.zero_grad()\n",
        "\n",
        "    data = tokenizer(data).to(device)\n",
        "    target = tokenizer(target).to(device)\n",
        "\n",
        "    out = model(data)\n",
        "\n",
        "    train_acc = float((out.argmax(dim=1) == target).sum()/batch_size)\n",
        "    train_acc_mean += train_acc\n",
        "\n",
        "    target = F.one_hot(target, num_classes=num_dict).float()\n",
        "    loss = loss_fn(out, target)\n",
        "    loss.backward()\n",
        "    train_loss_mean += loss.item()\n",
        "\n",
        "    optim.step()\n",
        "\n",
        "    pbar.set_postfix({\"Loss\": loss.item(), \"Accuracy\": train_acc}, refresh=True)\n",
        "\n",
        "  for data, target in (pbar := tqdm(valid_dataloader)):\n",
        "    with torch.no_grad():\n",
        "      data = tokenizer(data).to(device)\n",
        "      target = tokenizer(target).to(device)\n",
        "\n",
        "      out = model(data)\n",
        "      valid_acc = float((out.argmax(dim=1) == target).sum()/batch_size)\n",
        "      valid_acc_mean += valid_acc\n",
        "\n",
        "      target = F.one_hot(target, num_classes=num_dict).float()\n",
        "      loss = loss_fn(out, target)\n",
        "      valid_loss_mean += loss.item()\n",
        "\n",
        "      pbar.set_postfix({\"Loss\": loss.item(), \"Accuracy\": valid_acc}, refresh=True)\n",
        "\n",
        "  train_loss_list.append(train_loss_mean/len(train_dataloader))\n",
        "  valid_loss_list.append(valid_loss_mean/len(valid_dataloader))\n",
        "  train_acc_list.append(train_acc_mean/len(train_dataloader))\n",
        "  valid_acc_list.append(valid_acc_mean/len(valid_dataloader))\n",
        "\n",
        "  print(f\"Train_loss: {train_loss_mean/len(train_dataloader)}\")\n",
        "  print(f\"Valid_loss: {valid_loss_mean/len(valid_dataloader)}\")\n",
        "  print(f\"Train_acc: {train_acc_mean/len(train_dataloader)}\")\n",
        "  print(f\"Valid_acc: {valid_acc_mean/len(valid_dataloader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vn2FHAdw0W1B"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
